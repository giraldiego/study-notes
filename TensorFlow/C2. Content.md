# C2 - Convolutional Neural Networks in TensorFlow

## Week 1

In the first course in this specialization, you had an introduction to TensorFlow, and how, with its high level APIs you could do basic image classification, and you learned a little bit about Convolutional Neural Networks (ConvNets). In this course you'll go deeper into using ConvNets will real-world data, and learn about techniques that you can use to improve your ConvNet performance, particularly when doing image classification!In Week 1, this week, you'll get started by looking at a much larger dataset than you've been using thus far: The Cats and Dogs dataset which had been a Kaggle Challenge in image classification!

### Learning Objectives
---
-   Gain understanding about Keras’ utilities for pre-processing image data, in particular the ImageDataGenerator class
-   Develop helper functions to move files around the filesystem so that they can be fed to the ImageDataGenerator
-   Learn how to plot training and validation accuracies to evaluate model performance
-   Build a classifier using convolutional neural networks for performing cats vs dogs classification
---


### Larger Dataset
Generator, Validator, Define model, Compile, Train

```python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255.
train_datagen = ImageDataGenerator( rescale = 1.0/255. )
test_datagen  = ImageDataGenerator( rescale = 1.0/255. )

# --------------------
# Flow training images in batches of 20 using train_datagen generator
# --------------------
train_generator = train_datagen.flow_from_directory(train_dir,
                                                    batch_size=20,
                                                    class_mode='binary',
                                                    target_size=(150, 150))     
# --------------------
# Flow validation images in batches of 20 using test_datagen generator
# --------------------
validation_generator =  test_datagen.flow_from_directory(validation_dir,
                                                         batch_size=20,
                                                         class_mode  = 'binary',
                                                         target_size = (150, 150))```

### Fixing through cropping

### Visualizing the effect of the convolutions

In this lab, you will first review how to build CNNs, prepare your data with `ImageDataGenerator` and examine your results. You'll follow these steps:

1.  Explore the example data of `Dogs vs. Cats`
2.  Build and train a neural network to classify between the two pets
3.  Evaluate the training and validation accuracy

**Detailed steps:**

- Dowload the dataset as a zip
- Extract the dataset to the filesystem and explore it
- Display a preview of the images in the dataset using matplotlib
- Define a sequential model
- Compile the model: setting optimizer, loss and metrics
- Setup data and validation image generators
- Train and watch log outputs
- Visualize intermediate representations through the model
- Evaluate the accuracy and loss for the model

### Assignment

#### Cats vs. Dogs _(C2W1_Assignment.ipynb)_
- Download the images
- Create directory structure
- Split and filter dataset (train and validation)
- Create generators


### Ungraded Labs

1. Using more sophisticated images with Convolutional Neural Networks _(C2_W1_Lab_1_cats_vs_dogs.ipynb)_
---

## Week 2 - Augmentation

https://keras.io/api/layers/preprocessing_layers/

https://keras.io/preprocessing/image/

Take a look at the [ImageDataGenerator](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) which you have been using to rescale the image. There are other properties on it that you can use to augment the image.

```

# Updated to do image augmentation

train_datagen = ImageDataGenerator(
rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True,
fill_mode='nearest')
```

  These are just a few of the options available. Let's quickly go over it:

* `rotation_range` is a value in degrees (0–180) within which to randomly rotate pictures.
* `width_shift` and `height_shift` are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.
* `shear_range` is for randomly applying shearing transformations.
* `zoom_range` is for randomly zooming inside pictures.
* `horizontal_flip` is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).
* `fill_mode` is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.

### Assignment

- Cats vs. Dogs using Augmentation _(C2W2_Assignment.ipynb)_

### Ungraded Labs

1. Cats vs. Dogs with Augmentation _(C2_W2_Lab_1_cats_v_dogs_augmentation.ipynb)_
2. Horses vs. Humans with Augmentation _(C2_W2_Lab_2_horses_v_humans_augmentation.ipynb)_
---

## Week 3 - Transfer Learning

- You will see Transfer Learning, and how you can take an existing model, freeze many of its layers to prevent them being retrained, and effectively 'remember' the convolutions it was trained on to fit images.
- You will add your own DNN underneath this so that you could retrain on your images using the convolutions from the other model.
- You will learn about regularization using dropout to make your network more efficient in preventing over-specialization and thus overfitting.

### Transfer Learning with Inception
1. Download the pretrained weights
2. Import keras models and layers APIs
3. Setup the model for:
	- input shape
	- don't include the top layer
	- don't use the default weights from Keras

4. Load the downloaded weights into the model with `.load_weights()` 
5. Iterate thorugh the model's layers and disable the training on them
6. You can inspect the model summary
7. Select a layer `.get_layer()` using its name as last layer of the base model and input layer for your model
8. Also get the last output of the model  with `layer.output`
9. Create the final model by adding some additional layers on top of the pre-trained model.You will need to use Tensorflow's [Functional API](https://www.tensorflow.org/guide/keras/functional)
10. Flatten the output layer to 1 dimension
11. To prevent overfitting, add a [Dropout](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) layer befor the last one. `layers.Dropout`
12. Add a dense layer and a last layer according to your classes
13. Append your network to the base model

> For more on how to freeze/lock layers, you can explore the [documentation here.](https://www.tensorflow.org/tutorials/images/transfer_learning "https://www.tensorflow.org/tutorials/images/transfer_learning")

### Assignment
- Horses vs. Humans using Transfer Learning _(C2W3_Assignment.ipynb)_

### Ungraded Labs
1. Exploring Transfer Learning _(C2_W3_Lab_1_transfer_learning.ipynb)_
---

## Week 4 - Multiclass Classifications

### Changes to workflow: 

```python
# At flow_from_directory:
class_mode ='categorical'

# At models.Sequential
activation='softmax'

# At model.compile
loss='categorical_crossentropy'
```

### Assignment

1. [Multi-class Classifier _(C2W4_Assignment.ipynb)_](https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C2/W4/assignment/C2W4_Assignment.ipynb)

- Parsing the dataset
	- 1. One is to use `csv.reader` and create a for loop that reads from it
	- 2. The other one is to use `np.loadtxt`. You can find the documentation [here](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html).

- Visualizing the numpy arrays

- Creating the generators for the CNN
	- The images in this dataset come in the same resolution so you don't need to set a custom `target_size` in this case. In fact, you can't even do so because this time you will not be using the `flow_from_directory` method (as in previous assignments). Instead you will use the [`flow`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow) method.
	- You need to add the "color" dimension to the numpy arrays that encode the images. These are black and white images, so this new dimension should have a size of 1 (instead of 3, which is used when dealing with colored images). Take a look at the function [`np.expand_dims`](https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html) for this.

- Coding the CNN
```python
model.compile(optimizer = "rmsprop",
loss = "sparse_categorical_crossentropy",
metrics=["accuracy"])
```

### Ungraded Labs

1. [Classifying Rock, Paper, and Scissors _(C2_W4_Lab_1_multi_class_classifier.ipynb)_](https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/main/C2/W4/ungraded_lab/C2_W4_Lab_1_multi_class_classifier.ipynb)

For practice, you can search for other datasets (e.g. [here](https://archive.ics.uci.edu/ml/datasets.php) with more classes and revise the model to accomodate it.

---

## What have we seen so far?

You're coming to the end of Course 2, and you've come a long way! From first principles in understanding how ML works, to using a DNN to do basic computer vision, and then beyond into _convolutions_.

With convolutions, you then saw how to extract features from an image, and you saw the tools in TensorFlow and Keras to build with convolutions and pooling as well as handling complex, multi-sized images.

Through this, you saw how overfitting can have an impact on your classifiers, and explored some strategies to avoid it, including _image augmentation_, _dropout_, _transfer learning,_ and more. To wrap things up, you looked at the considerations in your code to build a model for multi-class classification!